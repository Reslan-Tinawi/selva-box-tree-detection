{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e212a116",
      "metadata": {
        "id": "e212a116"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3fa0cf4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3fa0cf4",
        "outputId": "298c8fd6-0f12-49c1-ce88-712a6c38a885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/backends/__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
            "  self.setter(val)\n"
          ]
        }
      ],
      "source": [
        "# detect if running in colab\n",
        "try:\n",
        "    import google.colab\n",
        "\n",
        "    ! pip install torchmetrics\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "import gc\n",
        "import math\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "from pprint import pprint\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import wandb\n",
        "from datasets import load_from_disk\n",
        "from PIL.TiffImagePlugin import TiffImageFile\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
        "from torchvision import tv_tensors\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.transforms import v2 as T\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# --- A100 OPTIMIZATION: ENABLE TF32 ---\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2739ce5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2739ce5",
        "outputId": "9fa6b491-a23c-4ff0-8bcf-d9322077ccf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    BASE_PATH = \"/content/drive/MyDrive/datasets/SelvaBox/saved/\"\n",
        "else:\n",
        "    BASE_PATH = \"../data/selvabox/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608af95d",
      "metadata": {
        "id": "608af95d"
      },
      "outputs": [],
      "source": [
        "def setup_seed(seed):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "setup_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57fcb61a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57fcb61a",
        "outputId": "61405965-6032-465a-f4c7-f2da18051c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12cfc353",
      "metadata": {
        "id": "12cfc353"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e4abc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "3767538a7af64246bf3ef23f8f385d9e",
            "4352f14c46ff401d963df654f3097575",
            "58f679e85b124392a9c2c03ecb852ad7",
            "b865746972b84d00801e6176332ddf68",
            "90a51907a3a14870b379853bf85c097b",
            "26e6193f0e0e4729aebfbc9884971ec6",
            "1658d9ef91974f83bb5ebcad1da5bd30",
            "f0e5dd3ad9c3432095d141fbfdc03768",
            "34a932bf66d048c2b507ea92b60e015f",
            "6c4f936f6ddb40339ca5c3158ba912c2",
            "92ef2f387e874a0b828130f10d9f615e",
            "e9e4c52159d641be96ab68fca2c3b03f",
            "41b5f4b669f3485091b2076ff4fe7b96",
            "974a64bdf820435197ba04bebfd7dcc9",
            "4aad43b36e8c496c9ca16565751a2391",
            "675911d47d5e4b2e848f3e3dd479295b",
            "203979e1c52c4be7a5a720f24f33a3ee",
            "43f2665f4fa4422ab4e9c2c421e49828",
            "beb4437ad73f480bb444807b7778c4b4",
            "f0d06b94999b44c58067b2a6f5d9d8ae",
            "49f726358d044504a85b61604257fccd",
            "efaa7b7b0e184a509671c87f67dc09c5"
          ]
        },
        "id": "a6e4abc0",
        "outputId": "9517e934-604e-42bf-e7a8-12ed3f230422"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3767538a7af64246bf3ef23f8f385d9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading dataset from disk:   0%|          | 0/34 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e4c52159d641be96ab68fca2c3b03f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading dataset from disk:   0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hf_train_ds = load_from_disk(BASE_PATH + \"train\")\n",
        "hf_val_ds = load_from_disk(BASE_PATH + \"validation\")\n",
        "hf_test_ds = load_from_disk(BASE_PATH + \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5236f98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5236f98",
        "outputId": "fe2f5de1-51f2-48b5-9b42-b0b1b5f18009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 585\n",
            "Number of validation samples: 387\n",
            "Number of test samples: 1477\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training samples: {len(hf_train_ds)}\")\n",
        "print(f\"Number of validation samples: {len(hf_val_ds)}\")\n",
        "print(f\"Number of test samples: {len(hf_test_ds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27dc1b0e",
      "metadata": {
        "id": "27dc1b0e"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aa1b9bc",
      "metadata": {
        "id": "7aa1b9bc"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=5, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_score = -float(\n",
        "            \"inf\"\n",
        "        )  # Looking for max mAP, so init with negative inf\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, current_score):\n",
        "        # Logic for maximizing metric (mAP)\n",
        "        if current_score > (self.best_score + self.min_delta):\n",
        "            self.best_score = current_score\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            print(\n",
        "                f\"   --> EarlyStopping counter: {self.counter} out of {self.patience}\"\n",
        "            )\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27637719",
      "metadata": {
        "id": "27637719"
      },
      "outputs": [],
      "source": [
        "def plot_image(\n",
        "    img, boxes, scores=None, labels=None, class_names=None, save_path=None, show=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots bounding boxes on an image with optional scores and labels.\n",
        "\n",
        "    Args:\n",
        "        img (np.array | torch.Tensor): Input image. Shape [H, W, C] (numpy) or [C, H, W] (torch).\n",
        "        boxes (np.array | torch.Tensor): Bounding boxes [N, 4] format (xmin, ymin, xmax, ymax).\n",
        "        scores (np.array | torch.Tensor, optional): Confidence scores [N]. Defaults to None.\n",
        "        labels (np.array | torch.Tensor, optional): Class indices [N]. Defaults to None.\n",
        "        class_names (list, optional): List of class string names. Defaults to None.\n",
        "        save_path (str, optional): Path to save the figure. Defaults to None.\n",
        "        show (bool, optional): Whether to display the plot. Defaults to True.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Data Standardization ---\n",
        "    # Convert PyTorch tensors to Numpy if necessary\n",
        "    if isinstance(img, torch.Tensor):\n",
        "        img = img.cpu().numpy()\n",
        "        # If image is [C, H, W], transpose to [H, W, C] for Matplotlib\n",
        "        if img.shape[0] < img.shape[2]:\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "    if isinstance(boxes, torch.Tensor):\n",
        "        boxes = boxes.cpu().numpy()\n",
        "\n",
        "    if isinstance(scores, torch.Tensor):\n",
        "        scores = scores.cpu().numpy()\n",
        "\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "    # Normalize image range if it's float 0-1, mostly for display consistency\n",
        "    # (Matplotlib handles 0-1 floats or 0-255 ints, but mixing is bad)\n",
        "    if img.dtype == np.float32 or img.dtype == np.float64:\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "    # --- 2. Setup Figure ---\n",
        "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
        "    ax.imshow(img)\n",
        "\n",
        "    # --- 3. Color Setup ---\n",
        "    # If no class names provided, default to a generic list\n",
        "    if class_names is None:\n",
        "        if labels is not None:\n",
        "            max_label = int(np.max(labels))\n",
        "            class_names = [f\"Class {i}\" for i in range(max_label + 1)]\n",
        "        else:\n",
        "            class_names = [\"Object\"]\n",
        "\n",
        "    # Generate distinct colors for classes\n",
        "    cmap = plt.get_cmap(\"tab20b\")\n",
        "    colors = [cmap(i) for i in np.linspace(0, 1, len(class_names))]\n",
        "\n",
        "    # --- 4. Plotting Loop ---\n",
        "    for i, box in enumerate(boxes):\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "\n",
        "        # Determine Label\n",
        "        if labels is not None:\n",
        "            cls_id = int(labels[i])\n",
        "        else:\n",
        "            cls_id = 0  # Default to 0 if no labels provided\n",
        "\n",
        "        color = colors[cls_id % len(colors)]\n",
        "        class_name = (\n",
        "            class_names[cls_id] if cls_id < len(class_names) else f\"Class {cls_id}\"\n",
        "        )\n",
        "\n",
        "        # Draw Rectangle\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "        rect = patches.Rectangle(\n",
        "            (xmin, ymin), width, height, linewidth=2, edgecolor=color, facecolor=\"none\"\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # Build Text String\n",
        "        display_text = class_name\n",
        "        if scores is not None:\n",
        "            display_text += f\" {int(100 * scores[i])}%\"\n",
        "\n",
        "        # Draw Text with background\n",
        "        ax.text(\n",
        "            xmin,\n",
        "            ymin,\n",
        "            display_text,\n",
        "            color=\"white\",\n",
        "            fontsize=10,\n",
        "            verticalalignment=\"top\",\n",
        "            bbox={\n",
        "                \"color\": color,\n",
        "                \"pad\": 2,\n",
        "                \"alpha\": 0.8,\n",
        "            },  # Added alpha for better visibility\n",
        "        )\n",
        "\n",
        "    plt.axis(\"off\")  # Hide axes ticks\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f449d8",
      "metadata": {
        "id": "06f449d8"
      },
      "source": [
        "# Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dab0988d",
      "metadata": {
        "id": "dab0988d"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    \"project_name\": \"selva-box-tree-detection\",  # WandB project name\n",
        "    \"name\": \"vanilla-fasterrcnn-experiment\",\n",
        "    \"num_classes\": 2,  # Background + your classes (e.g., 1 class + 1 background = 2)\n",
        "    \"batch_size\": 16,\n",
        "    \"num_workers\": 4,\n",
        "    \"num_epochs\": 20,\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight_decay\": 0.0005,\n",
        "    \"step_size\": 3,  # Scheduler step size\n",
        "    \"gamma\": 0.1,  # Scheduler gamma\n",
        "    \"patience\": 5,  # Early stopping patience\n",
        "    \"device\": device,\n",
        "    \"model_name\": \"fasterrcnn_resnet50_fpn\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "4a6d755c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "4a6d755c",
        "outputId": "a5727bbc-266d-45cd-b80e-01dbea11fdab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260115_190535-rzba8qg6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/warwick-team/selva-box-tree-detection/runs/rzba8qg6' target=\"_blank\">vanilla-fasterrcnn-experiment</a></strong> to <a href='https://wandb.ai/warwick-team/selva-box-tree-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/warwick-team/selva-box-tree-detection' target=\"_blank\">https://wandb.ai/warwick-team/selva-box-tree-detection</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/warwick-team/selva-box-tree-detection/runs/rzba8qg6' target=\"_blank\">https://wandb.ai/warwick-team/selva-box-tree-detection/runs/rzba8qg6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/warwick-team/selva-box-tree-detection/runs/rzba8qg6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7bd790989760>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project=CONFIG[\"project_name\"],\n",
        "    name=CONFIG[\"name\"],\n",
        "    config=CONFIG,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "120a60b9",
      "metadata": {
        "id": "120a60b9"
      },
      "source": [
        "# Custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a75b3b19",
      "metadata": {
        "id": "a75b3b19"
      },
      "outputs": [],
      "source": [
        "# inspired from: https://docs.pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
        "class SelvaBoxDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, n_classes=1, transforms=None):\n",
        "        self.dataset = hf_dataset\n",
        "        self.n_classes = n_classes\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.dataset[index]\n",
        "        image: TiffImageFile = sample[\"image\"]\n",
        "        annotations_dict = sample[\"annotations\"]\n",
        "\n",
        "        if image.mode != \"RGB\":\n",
        "            image = image.convert(\"RGB\")\n",
        "\n",
        "        # PIL returns (Width, Height)\n",
        "        w, h = image.size\n",
        "\n",
        "        image = tv_tensors.Image(image)\n",
        "\n",
        "        # number of objects/trees in the image\n",
        "        num_objs = len(annotations_dict[\"bbox\"])\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": tv_tensors.BoundingBoxes(\n",
        "                data=annotations_dict[\"bbox\"],\n",
        "                format=\"XYWH\",  # COCO format\n",
        "                canvas_size=(h, w),\n",
        "            ),\n",
        "            \"labels\": torch.ones((num_objs,), dtype=torch.int64),\n",
        "            \"image_id\": torch.tensor(\n",
        "                index\n",
        "            ),  # TODO: is this necessary? when moving data to GPU, it expects a tensor\n",
        "            \"area\": torch.tensor(annotations_dict[\"area\"], dtype=torch.float32),\n",
        "            \"iscrowd\": torch.tensor(annotations_dict[\"iscrowd\"], dtype=torch.int64),\n",
        "        }\n",
        "\n",
        "        if self.transforms:\n",
        "            image, target = self.transforms(image, target)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97ca6b4e",
      "metadata": {
        "id": "97ca6b4e"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61127843",
      "metadata": {
        "id": "61127843"
      },
      "outputs": [],
      "source": [
        "transforms = T.Compose(\n",
        "    [\n",
        "        T.ConvertBoundingBoxFormat(format=\"XYXY\"),  # Convert COCO format to xyxy\n",
        "        T.ToDtype(torch.float, scale=True),\n",
        "        T.ToPureTensor(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdfc9f19",
      "metadata": {
        "id": "cdfc9f19"
      },
      "outputs": [],
      "source": [
        "train_dataset = SelvaBoxDataset(hf_train_ds, transforms=transforms)\n",
        "val_dataset = SelvaBoxDataset(hf_val_ds, transforms=transforms)\n",
        "test_dataset = SelvaBoxDataset(hf_test_ds, transforms=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912dc664",
      "metadata": {
        "id": "912dc664"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=CONFIG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=CONFIG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=CONFIG[\"num_workers\"],\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b81deeeb",
      "metadata": {
        "id": "b81deeeb"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7845b388",
      "metadata": {
        "id": "7845b388"
      },
      "outputs": [],
      "source": [
        "def get_model(num_classes):\n",
        "    # Load a model pre-trained on COCO\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "    # Replace the classifier with a new one, that has num_classes\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28a3a844",
      "metadata": {
        "id": "28a3a844"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6077989",
      "metadata": {
        "id": "a6077989"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_cls_loss = 0.0\n",
        "    running_box_reg_loss = 0.0\n",
        "\n",
        "    for i, (images, targets) in tqdm(\n",
        "        enumerate(data_loader), total=len(data_loader), desc=f\"Training Epoch {epoch}\"\n",
        "    ):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        loss_value = losses.item()\n",
        "\n",
        "        # Specific losses for detailed logging\n",
        "        cls_loss = loss_dict[\"loss_classifier\"].item()\n",
        "        box_reg_loss = loss_dict[\"loss_box_reg\"].item()\n",
        "\n",
        "        if not math.isfinite(loss_value):\n",
        "            print(f\"Loss is {loss_value}, stopping training\")\n",
        "            print(\n",
        "                f\"Loss Dict: {loss_dict}\"\n",
        "            )  # Added print to see which specific loss failed\n",
        "            sys.exit(1)\n",
        "\n",
        "        losses.backward()\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss_value\n",
        "        running_cls_loss += cls_loss\n",
        "        running_box_reg_loss += box_reg_loss\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"train/batch_loss\": loss_value,\n",
        "                    \"train/batch_cls_loss\": cls_loss,\n",
        "                    \"train/batch_box_loss\": box_reg_loss,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader)\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_map(model, data_loader, device):\n",
        "    model.eval()\n",
        "    metric = MeanAveragePrecision(box_format=\"xyxy\", iou_type=\"bbox\")\n",
        "\n",
        "    for images, targets in tqdm(data_loader, desc=\"Validating\"):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        predictions = model(images)\n",
        "\n",
        "        predictions = [{k: v.cpu() for k, v in p.items()} for p in predictions]\n",
        "        targets_cpu = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
        "\n",
        "        metric.update(predictions, targets_cpu)\n",
        "\n",
        "    results = metric.compute()\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d02f4c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d02f4c2",
        "outputId": "42fb4e22-8ea5-4dbf-e324-84a487658f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 160M/160M [00:00<00:00, 234MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = get_model(CONFIG[\"num_classes\"])\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5caf4e44",
      "metadata": {
        "id": "5caf4e44"
      },
      "outputs": [],
      "source": [
        "# 4. Optimizer & Scheduler\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "    params,\n",
        "    lr=CONFIG[\"learning_rate\"],\n",
        "    momentum=CONFIG[\"momentum\"],\n",
        "    weight_decay=CONFIG[\"weight_decay\"],\n",
        ")\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer, step_size=CONFIG[\"step_size\"], gamma=CONFIG[\"gamma\"]\n",
        ")\n",
        "\n",
        "early_stopper = EarlyStopper(patience=CONFIG[\"patience\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ab7af05",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "217fa2a385da4efbbbd285556a28499e",
            "cd38dffcbc074380a12c89eed423a8ed",
            "09364ed8dc984f6ab943960efac65437",
            "cc5f60b11b4f4b4f8e02df7d11838297",
            "0fb39cf982d94c07a0556f7b4d2529c6",
            "00ded0bfeac5460ca3a90a298dfaec98",
            "203ce42eb1b14e7a891477a956fd75d2",
            "fbc092fe6d8341a0a2936ba4e8d13826",
            "f4e5614ad74d420490537676ff82f612",
            "afca4d4f5b16438a82360c419253384d",
            "e28831efcaed415996c191793fa7229c",
            "2279f2d55e6849598d90f54626de608d",
            "eb45043fe4c746a2b94ed386c8fe6222",
            "4177e01481ba459e83589b4f5b6192ff",
            "fdd11d162ade4ad1a71017fbe8f19914",
            "9d7c994e9cc44c12a116722247f8b55c",
            "3502e001efc545259591733eaeac66f5",
            "79f50615426440f58e82dd39e4c1e7e1",
            "9f8c36a85e54436ea438f6922a04e2dd",
            "e0e994a25c4446f48d3bde706f869d74",
            "449f2b956a2645d99340e1acf267c3cd",
            "e7182d03332a48d38d9dde8428e7f215",
            "eb8de1ec7989429f931ad6a9fea70554",
            "c3c80f413dd7434086e96752d7a2a7a6",
            "f8ec61d332e84acd99c9efc00387a782",
            "b24b2455cf9541cb84422420843b6d3c",
            "f3de6f1984594b6294e123613397fe69",
            "a5e5ad02db97466d879ecb8cd182bad1",
            "2c1bd3c00f2c45798b37b5a0224e7421",
            "8204993ef8f44551b45bec7dcb14c069",
            "b812aa9926a34220b53b89a2c19c42d0",
            "17a0f81afa2645029884daa9563d4ccc",
            "af363d9ed96d4bad97fdb4183b908bd6",
            "c95bfd83e67947719e3be798abfcad12",
            "945b298aad9441fa9ee1186874e2889c",
            "52b299ea4a17443999f6f9b7fc6b85fb",
            "40f984ab9ba84572a0daeb6b93c6e6f3",
            "0e2958706b1348c080dca8430e44088b",
            "adeda07d0fd543dcb8d8da298de4ce86",
            "01b8ba5912f14e949788782a8fb4debe",
            "b5353951dd4a4c2c9e54ffbe391a5299",
            "3433fbd8f78b4d40a432c303fdd17b08",
            "e2d35016c3ed4279ba7af00bfcaeaa30",
            "2603c6c8f680406b99fd4c22ad1a3b94",
            "db756be1e5c442a19abab33053a039f5",
            "c8d6d9ae501f4bffa229003cf711e99f",
            "3018cb8fa10540238488c0d6a1e13a74",
            "30cc3cb33f1e4a52819bd6c061cc43af",
            "8303f16235384c06917a65eeb617f2df",
            "109e7ff7ee364f96a481576250f61829",
            "2fee5bdd7ae64b96a50c34d43c653af8",
            "58c22a09497b49b09279655a53e03c46",
            "9a49d1087eb64ab1b260d31c47336c24",
            "02f9a06c53cb4df89c5428a880b88fc4",
            "cb384407ae5a41b896a38d453aa5566b",
            "a1e90059870f442cab8cb9bb4ed48f8f",
            "729c0aaad6d042088e941a5572652926",
            "272706dc0307411d954843d0d1793ff7",
            "d23c17beac6b448f9681e1f9a7a10d61",
            "337bc8b3f4da477b9041a68519b7c57d",
            "57e3921ae3064cd1ac3f47de7e8e6130",
            "def94df79a2b463180df849528ebf047",
            "f6462142d2174000b524c84acf82bfac",
            "192c194d7b064630a9b9d596ad0a8f82",
            "3b57315529e549fd9b7e9850c16849bc",
            "5ffc1ba963c645f48ea910fea615b02c",
            "aa22a1a9872f47c5b910c0ed75417b03",
            "b6820491a2164d4db7900aa0654d8c02",
            "21ed3d02652b4bebb154b855fb944740",
            "04cdbc30caff4e0db2fcb66e0a662a57",
            "4cf9a62fb1a5464d8ba46b78677204ed",
            "1cfe636c066c4d24954dcd41c8598d08",
            "738634be752d4aa5bb80dfe3261f5683",
            "c1f5b0f2c7cd4da486458630c969bec6",
            "8f0dc1695d2f44899c6d832ce4bf2157",
            "50ebd7f973964cb38024d4d2f2ae8983",
            "c93bb1c6c709485e9ff1b8b6b0e5359c",
            "01cb80449dea424e94359cfa3b9d14ec",
            "4ceebc655c494f6f80b78e6c94bf4785",
            "7e6bc6e12a564be2936972073facc769",
            "eeeeefe6146b419a8e1386a6289f855d",
            "25db63bbb99a4e8db21fd141971da9ab",
            "beb4492b25cf4a3f978af41af9b6be1b",
            "2074729b0b264678b7e4c5d24de73bd0",
            "3d5bbbfeb64f438481fb3e0ae64be8eb",
            "6a5d544c650c4f13b15abda59c3bc3c6",
            "1fe8f77cb1464fb495655df7d75e0178",
            "39fe1436aee442e3a02f3f3193821c59",
            "63d0f4de4a204ac39671db61592e14ef",
            "0b6907931e874ef8a5fbcbab0b449390",
            "79ae1ce4c57049329a20379b8992329e",
            "8b44552995314b9b8bfbd75206079287",
            "c67a6c1c57854af79f1ea3d4f0d97634",
            "b9c0114056b94ef1a54181cda495caed",
            "6a7ef1f525034ac7b719d4a506282e5d",
            "5f99f6e7289544e8aeb21115c504844b",
            "d89b107c134d4653a861b29262a3cbf1",
            "1d8fc909af3a4710ab145c03c5ae30a1",
            "5a873ece3fb24d5e9eaa74b7b00fc123",
            "dfe8fa4d6bc043298dc9efc38733bda9",
            "282736c70e7a40efa93e7c91cf7392f4",
            "13dba715d4b340198780d26cbb92b5d1",
            "a57ae1b6567549fc958a60788c25b05e",
            "cb41fd7248294b8a8719b7fb35320342",
            "f9d9b57d02db4a16908f88403f050efb",
            "9b0db0b34dc3494aa73d8ae2f38b6dd9",
            "f977582775924384adeef5db5dfa7757",
            "eb5a095a16a945dd9605542d8d13e67a",
            "f0e1a99f396b4e04bf1e2af75fbfe746",
            "49ca6f9df0a44f0ab23dbc3d9f38eca9",
            "29e7692f02f646b4a87e8eda56630940",
            "cfe0a230466444a99e3fe306fd1e00be",
            "ab3a22efa9224161a15c674547ce683f",
            "e28656831dc047d2be2e1bd3d6c2f9db",
            "4c27988895944cad9b5394b5d55bbf72",
            "130952b391e542bb8940127c65be5663",
            "1f01130761a44888acfe57fc71f07008",
            "d2c07be064f04082853cc05dc9bfc310",
            "34c287ea40834ff0bca57a38c0e41280",
            "d632d2cee4394e878a0a8c010a2a4644",
            "36509f29ec804633874a1fc10bedbf30",
            "70d247f588c7470bbfc9a680ce31ba52",
            "22414d8bd0f64ea7944ee188eb8f6279",
            "07b1e7bd73d7437cb2ebf4f5a5a967b0",
            "b23a94df4e05439791273452f3826e06",
            "f26eb584a33d4192b8af83e67faa012a",
            "cacd0bcc33fa4310a0f5bbfd310dbbf6",
            "c678816eeb094bce84fc14b14f28f939",
            "b3029f260a1a41a49ba88bc5e540ec72",
            "7526504fa8754c69aaaf33bde82d81ca",
            "5f41b471377f43a484bf01224ce68ad9",
            "d73f8a7cc6f04d7a876750bb56fa5cda",
            "b64812b08ec9420ba319b20f2002c538",
            "7795c037bc1947338d216c19636d7503",
            "08a8725107a84d3d9f0c89fd2b1b95c7",
            "a9c900685adf4d7db86095ec09b8fbd6",
            "14ca6ffe0c9d4e3a91e0f76199483d35",
            "7e47b6d04af844a7b2334c522d0a4f54",
            "d90dc5a3a9cc4eb9b12ad7de5fe56e9b",
            "d57e26dd10904e14857e426b1d1a9fb5",
            "a13ff7d78db2437fb56b48b38265ede0",
            "fddd25efa0ca4e79a5cf576d04e8d0c4",
            "3d638e0a1a494f468afa9ddc71786a2b",
            "9948842fc6564a11a0705b1a25ff70fc",
            "532f88c9c4da434980a40e387917db77",
            "a373fdb162f34325a5c26066fc04d6a1",
            "a22752916ea64ff7a73ee728e65ab19b",
            "d9fdebb70283479c9290366dddff09e3",
            "53a22d684c904edd9812b1f4f7afe652",
            "2a9a0fa0c01d4dca89e22bdffbff36b5",
            "f57a01c00f484ca09cb405d05d725fe4",
            "6f5758eb8a49444baa1f6301a121fda9",
            "7e19524b12a34dc8a0e408e1f743f4fe",
            "2e6388301db44ed3beb8f657e019d7a8",
            "dc577afad10d45b6a9c942b25fd6e5fa",
            "8fc3add31f0049de8b9bbc9caade3b46",
            "f825972c7fa049439f6a3e1ed9afba00",
            "7b165884bc30438d89e99ecef84fc2fd",
            "eda68989e41a43b58903419ee6ca0a6d",
            "14df5577747e4d7d9a7bf86ba4869983",
            "6a1d983b1d2d4c4b96489c1219fea0ba",
            "33edf1b6a820411db55033d4d2806811",
            "2f72cc6285174509a949ca7cfcf9ec4f",
            "36508c4ccf4542f6bc337042b5250338",
            "99d9f1d85e774d71b746df1f665bee6f",
            "5e48ed062dee43a2b5962ede5b188647",
            "88e2bbc3deff4d2cadf92d4727c942b5",
            "710350e147d34837a3503eae28f1acfd",
            "fdf749f5d54b4708865786452562eb41",
            "38ca483fdfdd465dad93cc568795f9a9",
            "2c539da9c03441aaa82d8080eff91ddd",
            "1402af12dc00491ab4786691c1c4c9a0",
            "c4f1b2a40f09496c9d84699fd6a8fb34",
            "b47a8372ffc84946967d7093ac950b50",
            "cc163c4735074495a297e1d6af463c84",
            "be69b7b080244a56887bab4b5c948417",
            "5d842ca405fe4db1b4caa185ffc15176",
            "28264ef4c05b4925a047dd0fbf9f0ae8",
            "7e03636c0a0e440783ea926c1b829fb1",
            "de4caa3080f44a558d6aedf2dfcf08ba",
            "8c991d8aeb3644d8a45ca87225166d1e",
            "209cdadb795b48eca3747c08fa137ea7",
            "3b520b2858614e829e186565a4b28bdd",
            "3773f39ff3524e1782431ab6d77de97c",
            "628a80cd36bc42c0b17d602cbac32225",
            "3810c94ac6124ff1a19793e3d44b3105",
            "2c64d678e2394b32a16b75088cab4828",
            "c3285ff963bf49198ac0081a1cb11e81",
            "458f20eba7ae4d8087f8062dccbc0bcd",
            "387f3730e7d94a73ab03e866c083f073",
            "3ecb7b16c0c24c69bbff4cb309883970",
            "3a7343feb202458587eb5ce4d9951918",
            "3ae252d8baa84f10b6c634fc77306675",
            "e5ff71e96d074975b59777f399518468",
            "d99f286ccd1246eaaf83cb735f2b0d94",
            "3f46684e0f5b4597bf1c4380a316661b",
            "93b19dca876d4044a844eb2699bf394b",
            "ce1e50d1176940d2b93e9276f0331ef6",
            "a1ce0f10dab54f6499813cccf29c3e7f",
            "ce6632fc083f441683481f767f127776",
            "469973c2cbb24bc396d221fbb317e0ac",
            "a138886fd4684324a8f2271380585c6a",
            "3510a45586ae4056888f3c25dc0cdb99",
            "0962b359b8c74b44a93e5355fdeb0e79",
            "722b98debcec4eed86561ad9624972d1",
            "bdd853ba0f8f4d4ebc9055ef4b9d1f21",
            "1457d4d589ec4929afb9085344ec93e4",
            "81ba432274f84659ab900cc6f7e8f5cd",
            "d3bd3636365a4ad597f0785936fb2650",
            "d10d44c8a74241f4ac72139e9bc9cc22",
            "c5913572eecb4838a4893672a1ce8250",
            "1d2f9052d57f4f27943a184eb28efff6",
            "6bef2b8981ff4632bb9305b1de8adf52",
            "80a62469bbfe44d886c5741e1afc13b6",
            "811471dfdbff462ca26f1f02e4870516",
            "4e5f395571254c4fa1719dc0c6bacba3",
            "e08760ce7c2d4ae986f78c700c2b746f",
            "cb3a0a1955ae4343bf178e995c73b845",
            "64a8ce63fb504f03b94beed21ec3ca03",
            "3a303bae2209468a9ce4b597ef9c8f04",
            "74ccd7529b704cdd94d4fb2026c4d08f",
            "11f9ea99c7a4497d92ea0875e6f3fffc",
            "44e11f10f2ef4549b72fa4aa2a9e01be",
            "3a3d0666569542c0ae25785351f4808d",
            "c54be1c028664b33bebf41bc09645877",
            "ba65352662df44089c27f88affdcecf7",
            "893e9767e7dd4d3aaabc915a61f6fe43",
            "f0dd3aa12e6f4b06b625e47fdbc463c3",
            "c5eca01187a84d54aff0be6e6fcbe85b",
            "8e41f23aaee24a8dab697b5f0e6b9bce",
            "04a22784f65b417a917d5fb97ac7b7e0",
            "34965278868549fd898862b960cb0976",
            "577365b4ec344fa3a8c23a5e5e26af0a",
            "f9fb79f85cea432e91937dededd7716e",
            "997832fa44b145dfb242997f1243309b",
            "602ecec4a5304545b456635aa8bd1ad7",
            "0c3da7edfa7640cf8953b140ad4836cb",
            "f426dbc94ced4399adf69ebb8ace8ae5",
            "dbb25fe1a2684401b0f088c468bb2439",
            "a93d68f5ef9e4b3b96dbf3dd57f269aa",
            "111ba16226b942d682ecfec7a4c753b6",
            "0d7e8f11864e4305832377eeebff507d",
            "e269f1b4b3b74000b7e16f025602bd1c",
            "7b7d2afd1b3241cd98d32791bad0621d",
            "7695d25ccb82424785bcb48a23a0301b",
            "3f5ea8b4174946dc814c84b968a4c4c0",
            "e17274d8162a4c049a72ac0a201efbb3",
            "fa8a2a8d63f5460c965ffdbf2bc1678c",
            "cd6406e4038749d0bac3fa18743d0ccf",
            "981e9297cbcf4f19b0c2ad864583cb62",
            "31c6a5c152e542dd9c77f55286d337a7",
            "310eecc7080d4048b7e04e9a58844ecb",
            "9ea7eb751aff4f03a33cbb4a9d020d21",
            "72941ab2d2724f6ba9288994d346bd97",
            "cfbe51f8fae54d33b965378392a014b5",
            "b798fc3e43af4ddaa36f6d83185b8777",
            "bed2eddbefb245128162bec328d35452",
            "debac03386224967ac6063c079dce6fa",
            "e0a8c4f6f78744a08b3edb6fea0af314",
            "2b85c8783f6844139a8b5ea889fd50e0",
            "b2477fbca1ae4910a3dbaf3ce98da106",
            "adc630902f5a4149a0d627dc6807f291",
            "1743a52e14af47339bc0ad2e7d137fbc",
            "f119e16c2d5e4e768728ed216d922d3c",
            "af3589f8529344b48e9e550082bb4a78",
            "0160b76586434ba3ad13ece69fc35db6",
            "c4844e994f2446729c6331fe9d90f83e",
            "413402c9fbaf4f428ef0268adf5fbbf9",
            "a1c6874dade144d88402f18914fd642c",
            "dbab6df86b5b4efba554aa55b3fb1934",
            "d6684cffdb724424ab0c6887c9aed6ee",
            "2e38bf3e56374da7a27e621a448f631e",
            "7fd3fff641a149af8593dccb6690d786",
            "91edb9b9a1594e888516e8eab2d69864",
            "211afaacbab846fca79e42c387c12bc2",
            "71e40b02e1ca48ff9299da70c79672e9",
            "2c65eb893ca8405e845d339b2b81a30c",
            "8fc54b8e681c489cb59fcb0e87a2a8e4",
            "042f21bd937541f3aa8e80d200e41e14",
            "50dba95ea7a14fdab14780eb78950a8c",
            "78530dd19c6e49df84f700698db26267",
            "ad6daaf90c6e4a91ad1bcbe45b44876b",
            "4ce6185e364047eabfc4dd96a282b906",
            "2b610bb881784adea52f9f9c76c9b86a",
            "f34b932e132940c6aa4d360cfc026c9e",
            "838e564c3d684542881218bd1f263800",
            "f44b08aa12974f428ddff570724fc2e5",
            "bcef609921574191a27f6732a079cb27",
            "52377fbe43004fb6ab4f74d1bb3e2640",
            "fe89777e94ae4d948977087cecb74ad8",
            "65b7bd4926684d928e2f4e1fed6948b6",
            "cb9bfd94ab5f4bf8996a95ec6f404dce",
            "bdfe9efc51ba4285b4169e2f3371d6be",
            "330c76fd7f51423fbd37f98f5c1eb752",
            "790320be8d2f42ac8c6fcca0a987296a",
            "dc1ba7c95d604213a6e7fa4384d62d14",
            "5e3d4cede8434879956fe8f85c665571",
            "e88dd28daa4f4d4d93fd05dc0cee0916",
            "08ee8775eab6429ebf4fd172e859ea09",
            "6438c74eb5504fb2a097b747b9097cdf",
            "882e2e8f84f74feea7dc7d31c4029e87",
            "b7ef0d23980d407aa6425fed17ccdc8d",
            "4cba60d739ad44709df2597c0ea8393b",
            "3bc03980d4504ba2b4e16d70081bcd57",
            "f207ba1b4f9c4dba9c65b40d86ee91dd",
            "b780490ba5c544298682f29fa7e594ed",
            "0b660157864c4747ba2590e9c1ad6ffc",
            "4800cb62e61243ac8fa69f0cc38e8eab",
            "07494fc7a28a462eb7aa897cf3f37aee",
            "0d6c22b393b84c4cb1388e76abbe4533",
            "e8666abc73774a84946bbb600e45e740",
            "57263a3750f74a35869efdaaf819b9fd",
            "2f3921768c3748e58fabe3effbabd209",
            "7a05ae15b2224d5e96447ef79536e2ff",
            "a07c58c3a4d240ccadb87bb92968739b",
            "d2ea0d37a1c84d9caefd8741dbdc1465",
            "9ba60613d9854bd288e15a715f9257fd",
            "116729b2b0a34daaa998f128ec5600b8",
            "7601fe4df6b4473faa1393756a0a71e3",
            "3226d4edf6b84fab831ab11d38ae2d9b",
            "acf11ace11994130bcb517b76730e2b1",
            "0a52cd3c7f704afe98506f4b8f6f0f42",
            "1766c4a1d50642519c9c7e0a41a39309",
            "2e79af41b04e45d4afc0118eb496562a",
            "538e0c5e74e14fb59008e5ed40e74bf8",
            "2dd2c30cf686402d90f84c3b32f93145",
            "eecd7e3f087c4c8aa44a987ff0b29400",
            "2f5e04c17c0e4350b4aad15b0fb839b9",
            "d0deaef47e964e26a6c81c3122efda55",
            "ff389c34274c4d7992a2fd2e13c41a7c",
            "81dc6b5b58f44950b80f39a7cac1de12",
            "15e4e732bb7b47dca4a72bb8d899a4e1",
            "d4d3975079994ac89def3b8f38a2fac2",
            "408a74f5159347048bb417174d178869",
            "e8666a38dcdb44bdb9cd05a60d009832",
            "d8e49fabfc1c47c78eff0332968d0bdc",
            "7e0f850c36d5473d94a68ee52af89363",
            "9444470af8704f16b09d187caf1ed975",
            "244dca4d848749bbbc7ec8d653192774",
            "8ff04588cbe342d29fd9242bf5504c1b",
            "1999e00ad1294f4db3897c75a18b093b",
            "2ffca11a035746a9922a4c165ac1ee58",
            "3eb2000f3c3d4d99a11c4eb251e545b5",
            "33a996f4b8ca427cb2e161f0822a61e5",
            "ae061eb547e747fb8a53d69940fa0f96",
            "658a1ed4292642a6a7f3bb071de9e7f4",
            "c70ba21c1e804fe1b9a9d971f419d236",
            "8fb2f6ba71fd46ea85d48b671a01a81d",
            "889d403557de4626a9c12ff47c6f33a8",
            "ae202cee98d0455791742da13f4f57b0",
            "640c7647081b46fd8a9dced6b63aea58",
            "c2cb3f74044d44338c102d2e519fcfc7",
            "bcf4f789597f4524bc6b3fe925668c32",
            "bc0bca374f2a417db89542c7fd4f6c2f",
            "abf72cffe65a4adc9c1f195019ab96a8",
            "72c90aa5a33a42cf9c384285d20a615e",
            "b82e541c9d4f4742b4ac304826843d67",
            "8e2e567e92a447eb82f6b3294a23cee1",
            "67af79f2c8fa472f98975a356abfe4d8",
            "88ced8d0c79f4d59af501b453bab4aca",
            "5ff822bbff2447409eb9527a1cd0b0ea",
            "71ce07851c3d49609f0c84f33534f6e4",
            "cf78e3249d9a440a92ac7642757c5518",
            "8f797bce47cd499d8e27e77a426441ef",
            "3d9c6f6f24a147d2ae073e26d782b0b9",
            "e6eae4fe73384d6fa84fa27d9e444862",
            "1df77f15516f432dbbd3c7b9310ec507",
            "fd9db8f80ca844278fbb2dc93bc98c2a",
            "aa5f7d0a344c4d23a248cbece2e6e838",
            "b08d4d68fe1548eb93f3e478a4b80c22",
            "fd631994f9b34293af6aaf8b9a4f4097",
            "3d119042bb764289936f871f71f21bf9",
            "5f5d0825371b4972b36266bc7b4e6c03",
            "65929c114b1e44ca9df91308086f8f8b",
            "10ad0f9db3cf446da825bf1e94cdef46",
            "d9ff86c5080c47bea97ab41eecf14d07",
            "23bda3e9b6724e56a1d73069ac23de66",
            "6768bfdd86f1467fbf40e85851668401",
            "06a9ab28afdd42e4bceeb8c1a336e6ad",
            "410524a96c914b718c4913d1851b1b29",
            "0d3af72bf5df49238376c499634ec890",
            "fcb83ea2a85b46159d44d8a71a4d0636",
            "5244fc2ce4f84833a1fa70186eabec11",
            "51af310a4e764361bf675f91970a2804",
            "e3ef2b45b1324f1290ecbbf6efa33cc9",
            "6bf72976b94244a0a2e27b63de7a868b",
            "ffd29ffb6c894e0197c1d15cd1264058",
            "2166f59012664c5b92a9308ba23e1c6e",
            "94f3385ee8084e5da3d976fabb7a48ce",
            "cb0197652cde4aa6b156935733418cb9",
            "5fc46839a2a348c3b2a1cfd1064e6b89",
            "d23d15ec06314210aa9000bdbf754f37",
            "a347c31bcb034740babad82ed9d6f676",
            "57fe2d1b3a8f4eae9c5ecc37b8960e42",
            "336cd445591448fb84cbe6e68052eb94",
            "ba27736f96e748979806e3ac0efbf686",
            "ef1c01290da547daa62c644b587e5805",
            "8b16bd71b80a4294836f9d61997d9474",
            "67e6c8956256465596acb7d1eda638ae",
            "f01586428af9488da782423f109de00d",
            "e917e68977614b95a3858c3df77d1825",
            "a0d3b48ad6e74b72b13b8e03b18f723a",
            "3ac0848c73e0473cb01fd8c31ccf3a1a",
            "2a70259eeba8467f9a1bf177d426cdce",
            "1f8613a1e8d44c508cbd203c4f6cb703",
            "eaca18fb952c43708e924e42ea1ed55e",
            "8aada1a4f8f2403e8f3d15fa3b39b13a",
            "b220c7a1b988444797e5b129f23c2371",
            "13f6ed529f6d49e59ec920f6b8a4c9be",
            "657e62485aeb494e818f5e761f7e5e4c",
            "3508f1bd3b534fcca4b3199891d7a0c2",
            "d25e24f17f7c44a395e9d20c31bdfb05",
            "8c15ed9eecdb4c3db5c46f9192b7992f",
            "3c363661915c49ae80f697aeba02fe5c",
            "7d6f3c6a51f243009710b1373fac7da7",
            "477f6f19c2f741cb940b7148581d04f9",
            "b541db175c18450d8ca3ebafd91f927c",
            "6dea90e6ecbf418288e9d5d3ea9ddeac",
            "5c82b9fda40a42219ece942af18ecd48",
            "787a421cca3f4874ae0d686a9950172a",
            "80bea640ef6f4a55879a819cf92ac1f1",
            "8b31f0f007a74bcab9dcfaebb1d5ee88",
            "e6912c71c6ab4d8ca80a7ee118f577fc",
            "b8a1d89e8ee34d31b5c20ed8b8557791",
            "6dd7ebba9de640789733faa5712b26c3",
            "fb80295fcbcd47efbc1c7aaaeff3cc15",
            "dd0b20e1ea8a4466a6b471f62f4681ef",
            "a28c8304592943c3ab49d1a6e2162047",
            "62ba896f060849dd908074b4f36a28c9",
            "90d331d0d8da41448cac15131bc59abd",
            "46e362c3117149838cee51c107fd32d0",
            "93da3c77e74849bfbd791e0142ce58a1",
            "dc0a19ec06194ee5afe4d40542b8ca74",
            "c25c388e53be40438220d3922f8a84c8",
            "1dc2470966c24f15a5f8521c86c516f2",
            "c2f55d238cfa48f5a2a2d93e176c5af3",
            "b3c6a1c22c6e4e69a241e65433e6145e",
            "53a0c49b5c894c459416736ba6cc039b",
            "e180cdc47acc46d891fcb005607b3eef",
            "c30b7dcf944f45efb6cb82495e82e67e",
            "f0f4297786bd4ca0be68f9397766262e",
            "492b23b6b47c48dbbc6b322d48f236ed",
            "c2e0040d7ea949c18b0c1b96c6f5929e",
            "e6104e784ca0422fad0bb7f59b519c73",
            "fc9819ca36fb4811b9b60b08758aba65",
            "58f80af9148f49a4a3426dec248dabb8",
            "bba1e8f63acb47899a92b9193361a809",
            "a9608a3b5b2d4cbb85a779cf12772aa1",
            "24061d5e11dc47dd9d0d72dad40aa990",
            "c1bbc0f33489439ea4807c81fb352b46",
            "9903daaa7d484c549f233649625bc44b"
          ]
        },
        "id": "3ab7af05",
        "outputId": "95e50a34-5b17-4788-bd0c-1900b9bd6e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "217fa2a385da4efbbbd285556a28499e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Overall Training Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2279f2d55e6849598d90f54626de608d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 0:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb8de1ec7989429f931ad6a9fea70554",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20] Train Loss: 2.7365 | Val mAP: 0.0457 | Val mAP_50: 0.1302 | Time: 3.7m | Peak Mem: 19347 MB\n",
            "--> New Best Model Saved (mAP: 0.0457)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c95bfd83e67947719e3be798abfcad12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 1:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db756be1e5c442a19abab33053a039f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20] Train Loss: 1.7214 | Val mAP: 0.0662 | Val mAP_50: 0.1610 | Time: 2.7m | Peak Mem: 19315 MB\n",
            "--> New Best Model Saved (mAP: 0.0662)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1e90059870f442cab8cb9bb4ed48f8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 2:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa22a1a9872f47c5b910c0ed75417b03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20] Train Loss: 1.6033 | Val mAP: 0.0950 | Val mAP_50: 0.2135 | Time: 2.7m | Peak Mem: 19091 MB\n",
            "--> New Best Model Saved (mAP: 0.0950)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01cb80449dea424e94359cfa3b9d14ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 3:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63d0f4de4a204ac39671db61592e14ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20] Train Loss: 1.5566 | Val mAP: 0.0886 | Val mAP_50: 0.2011 | Time: 2.7m | Peak Mem: 19597 MB\n",
            "   --> EarlyStopping counter: 1 out of 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfe8fa4d6bc043298dc9efc38733bda9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 4:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29e7692f02f646b4a87e8eda56630940",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20] Train Loss: 1.5476 | Val mAP: 0.0952 | Val mAP_50: 0.2142 | Time: 2.7m | Peak Mem: 19631 MB\n",
            "--> New Best Model Saved (mAP: 0.0952)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70d247f588c7470bbfc9a680ce31ba52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 5:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b64812b08ec9420ba319b20f2002c538",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20] Train Loss: 1.5414 | Val mAP: 0.0929 | Val mAP_50: 0.2070 | Time: 2.7m | Peak Mem: 19271 MB\n",
            "   --> EarlyStopping counter: 1 out of 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9948842fc6564a11a0705b1a25ff70fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 6:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc577afad10d45b6a9c942b25fd6e5fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20] Train Loss: 1.5412 | Val mAP: 0.0955 | Val mAP_50: 0.2137 | Time: 2.7m | Peak Mem: 19573 MB\n",
            "--> New Best Model Saved (mAP: 0.0955)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e48ed062dee43a2b5962ede5b188647",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 7:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d842ca405fe4db1b4caa185ffc15176",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20] Train Loss: 1.5380 | Val mAP: 0.0962 | Val mAP_50: 0.2150 | Time: 2.7m | Peak Mem: 19409 MB\n",
            "--> New Best Model Saved (mAP: 0.0962)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3285ff963bf49198ac0081a1cb11e81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 8:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1ce0f10dab54f6499813cccf29c3e7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20] Train Loss: 1.5396 | Val mAP: 0.0963 | Val mAP_50: 0.2154 | Time: 2.7m | Peak Mem: 19298 MB\n",
            "--> New Best Model Saved (mAP: 0.0963)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d10d44c8a74241f4ac72139e9bc9cc22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 9:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74ccd7529b704cdd94d4fb2026c4d08f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20] Train Loss: 1.5398 | Val mAP: 0.0964 | Val mAP_50: 0.2156 | Time: 2.7m | Peak Mem: 19482 MB\n",
            "--> New Best Model Saved (mAP: 0.0964)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34965278868549fd898862b960cb0976",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 10:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e269f1b4b3b74000b7e16f025602bd1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20] Train Loss: 1.5396 | Val mAP: 0.0964 | Val mAP_50: 0.2157 | Time: 2.7m | Peak Mem: 19531 MB\n",
            "--> New Best Model Saved (mAP: 0.0964)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72941ab2d2724f6ba9288994d346bd97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 11:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af3589f8529344b48e9e550082bb4a78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/20] Train Loss: 1.5392 | Val mAP: 0.0965 | Val mAP_50: 0.2157 | Time: 2.7m | Peak Mem: 19576 MB\n",
            "--> New Best Model Saved (mAP: 0.0965)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71e40b02e1ca48ff9299da70c79672e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 12:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f44b08aa12974f428ddff570724fc2e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/20] Train Loss: 1.5376 | Val mAP: 0.0965 | Val mAP_50: 0.2157 | Time: 2.7m | Peak Mem: 19090 MB\n",
            "--> New Best Model Saved (mAP: 0.0965)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e88dd28daa4f4d4d93fd05dc0cee0916",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 13:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07494fc7a28a462eb7aa897cf3f37aee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/20] Train Loss: 1.5340 | Val mAP: 0.0964 | Val mAP_50: 0.2157 | Time: 2.7m | Peak Mem: 19538 MB\n",
            "   --> EarlyStopping counter: 1 out of 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3226d4edf6b84fab831ab11d38ae2d9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 14:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81dc6b5b58f44950b80f39a7cac1de12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/20] Train Loss: 1.5377 | Val mAP: 0.0965 | Val mAP_50: 0.2158 | Time: 2.7m | Peak Mem: 19149 MB\n",
            "--> New Best Model Saved (mAP: 0.0965)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ffca11a035746a9922a4c165ac1ee58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 15:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcf4f789597f4524bc6b3fe925668c32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/20] Train Loss: 1.5406 | Val mAP: 0.0965 | Val mAP_50: 0.2157 | Time: 2.7m | Peak Mem: 19444 MB\n",
            "   --> EarlyStopping counter: 1 out of 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f797bce47cd499d8e27e77a426441ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 16:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10ad0f9db3cf446da825bf1e94cdef46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/20] Train Loss: 1.5377 | Val mAP: 0.0965 | Val mAP_50: 0.2158 | Time: 2.7m | Peak Mem: 19090 MB\n",
            "--> New Best Model Saved (mAP: 0.0965)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bf72976b94244a0a2e27b63de7a868b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 17:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef1c01290da547daa62c644b587e5805",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/20] Train Loss: 1.5372 | Val mAP: 0.0965 | Val mAP_50: 0.2158 | Time: 2.7m | Peak Mem: 19294 MB\n",
            "   --> EarlyStopping counter: 1 out of 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b220c7a1b988444797e5b129f23c2371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 18:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c82b9fda40a42219ece942af18ecd48",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/20] Train Loss: 1.5395 | Val mAP: 0.0965 | Val mAP_50: 0.2157 | Time: 2.7m | Peak Mem: 19221 MB\n",
            "   --> EarlyStopping counter: 2 out of 5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90d331d0d8da41448cac15131bc59abd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training Epoch 19:   0%|          | 0/37 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0f4297786bd4ca0be68f9397766262e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validating:   0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/20] Train Loss: 1.5388 | Val mAP: 0.0965 | Val mAP_50: 0.2157 | Time: 2.7m | Peak Mem: 18973 MB\n",
            "   --> EarlyStopping counter: 3 out of 5\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>learning_rate</td><td>██▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>system/peak_mem_mb</td><td>▅▅▂██▄▇▆▄▆▇▇▂▇▃▆▂▄▄▁</td></tr><tr><td>train/batch_box_loss</td><td>█▄▄▇▄▄▂▅▃▃▃▃▁▄▃▃▄▄▃▂▃▃▂▃▂▃▄▄▃▄▄▄▄▂▂▃▃▃▄▂</td></tr><tr><td>train/batch_cls_loss</td><td>██▆▆▃▂▂▂▁▂▁▂▁▁▂▂▂▁▁▂▁▁▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▂▁</td></tr><tr><td>train/batch_loss</td><td>█▄▄▄▂▂▂▁▂▂▂▂▁▁▂▂▁▂▁▂▁▁▁▂▂▁▂▁▂▂▁▂▁▂▂▁▁▂▂▂</td></tr><tr><td>train/epoch_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/mAP</td><td>▁▄█▇████████████████</td></tr><tr><td>val/mAP_50</td><td>▁▄█▇█▇██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>system/peak_mem_mb</td><td>18973.31445</td></tr><tr><td>train/batch_box_loss</td><td>0.40632</td></tr><tr><td>train/batch_cls_loss</td><td>0.3635</td></tr><tr><td>train/batch_loss</td><td>1.53133</td></tr><tr><td>train/epoch_loss</td><td>1.53881</td></tr><tr><td>val/mAP</td><td>0.09647</td></tr><tr><td>val/mAP_50</td><td>0.21575</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vanilla-fasterrcnn-experiment</strong> at: <a href='https://wandb.ai/warwick-team/selva-box-tree-detection/runs/9hc5liph' target=\"_blank\">https://wandb.ai/warwick-team/selva-box-tree-detection/runs/9hc5liph</a><br> View project at: <a href='https://wandb.ai/warwick-team/selva-box-tree-detection' target=\"_blank\">https://wandb.ai/warwick-team/selva-box-tree-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260115_174623-9hc5liph/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting training...\")\n",
        "\n",
        "best_map = 0.0\n",
        "\n",
        "# Memory tracking\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "start_train_time = time.time()\n",
        "\n",
        "for epoch in tqdm(range(CONFIG[\"num_epochs\"]), desc=\"Overall Training Progress\"):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # --- Train ---\n",
        "    avg_train_loss = train_one_epoch(\n",
        "        model, optimizer, train_loader, device, epoch\n",
        "    )\n",
        "\n",
        "    # --- Update Learning Rate ---\n",
        "    lr_scheduler.step()\n",
        "    curr_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    # --- Validation (Loss Proxy) ---\n",
        "    val_metrics = evaluate_map(model, val_loader, device)\n",
        "    val_map_50 = val_metrics[\"map_50\"].item()\n",
        "    val_map = val_metrics[\"map\"].item()\n",
        "\n",
        "    epoch_end = time.time()\n",
        "    epoch_duration = (epoch_end - epoch_start) / 60\n",
        "    peak_mem = torch.cuda.max_memory_allocated() / 1024 / 1024\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch + 1}/{CONFIG['num_epochs']}] \"\n",
        "        f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Val mAP: {val_map:.4f} | \"\n",
        "        f\"Val mAP_50: {val_map_50:.4f} | \"\n",
        "        f\"Time: {epoch_duration:.1f}m | \"\n",
        "        f\"Peak Mem: {peak_mem:.0f} MB\"\n",
        "    )\n",
        "\n",
        "    # --- Logging ---\n",
        "    wandb.log(\n",
        "        {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train/epoch_loss\": avg_train_loss,\n",
        "            \"val/mAP\": val_map,\n",
        "            \"val/mAP_50\": val_map_50,\n",
        "            \"learning_rate\": curr_lr,\n",
        "            \"system/peak_mem_mb\": peak_mem,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # --- Save Best Model ---\n",
        "    if val_map > best_map:\n",
        "        best_map = val_map\n",
        "        torch.save(\n",
        "            {\n",
        "                \"epoch\": epoch,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"map\": best_map,\n",
        "                \"config\": CONFIG,\n",
        "            },\n",
        "            \"baseline_faster_r_cnn.pth\",\n",
        "        )\n",
        "        print(f\"--> New Best Model Saved (mAP: {best_map:.4f})\")\n",
        "\n",
        "    # 6. Early Stopping\n",
        "    early_stopper(val_map)\n",
        "    if early_stopper.early_stop:\n",
        "        print(\"--> Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "    # 7. Flush Memory\n",
        "    del avg_train_loss, val_metrics\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "\n",
        "# wandb.finish()\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad30c1e5",
      "metadata": {},
      "source": [
        "# Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qsSA-PaO-8qp",
      "metadata": {
        "id": "qsSA-PaO-8qp"
      },
      "outputs": [],
      "source": [
        "model = get_model(CONFIG[\"num_classes\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4b157bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4b157bf",
        "outputId": "17a44648-6f42-411b-b87a-f58c1a670d91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): BackboneWithFPN(\n",
              "    (body): IntermediateLayerGetter(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (fpn): FeaturePyramidNetwork(\n",
              "      (inner_blocks): ModuleList(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): Conv2dNormActivation(\n",
              "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): Conv2dNormActivation(\n",
              "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (3): Conv2dNormActivation(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (layer_blocks): ModuleList(\n",
              "        (0-3): 4 x Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (extra_blocks): LastLevelMaxPool()\n",
              "    )\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load best model\n",
        "checkpoint = torch.load(\"baseline_faster_r_cnn.pth\")\n",
        "\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40dbd115",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 52,
          "referenced_widgets": [
            "6487c2a30e284f388def92f845512517",
            "d327088ce36f4f0c968480eb03698b1c",
            "6cfed2052b964db8ba22ff935f8e0f3b",
            "f6185e237e964a708acb1719f9d9e4f2",
            "11f86e62d1e24a9994ec7dc9c0f5d47d",
            "227c62630e434ca29c1cd5d372ebec97",
            "500b83bfe76e4808ba661c234acab7ae",
            "451394faee46459ba468a5e9c3ba0a18",
            "ddacf527c56a44e1a2a6da0be379eddc",
            "927f2adb345c4ee3bacc5cc1723bc373",
            "ac071f1ae6cd49fa9c544683595c0219"
          ]
        },
        "id": "40dbd115",
        "outputId": "9a7d8c73-5b62-4b45-c815-6054eacdeae7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6487c2a30e284f388def92f845512517",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing:   0%|          | 0/93 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mAP (IoU=0.50:0.95): 0.0928\n",
            "mAP (IoU=0.50): 0.2107\n",
            "mAP (IoU=0.75): 0.0680\n",
            "{'classes': tensor(1, dtype=torch.int32),\n",
            " 'map': tensor(0.0928),\n",
            " 'map_50': tensor(0.2107),\n",
            " 'map_75': tensor(0.0680),\n",
            " 'map_large': tensor(0.1295),\n",
            " 'map_medium': tensor(0.0334),\n",
            " 'map_per_class': tensor(0.0928),\n",
            " 'map_small': tensor(0.0035),\n",
            " 'mar_1': tensor(0.0054),\n",
            " 'mar_10': tensor(0.0416),\n",
            " 'mar_100': tensor(0.1565),\n",
            " 'mar_100_per_class': tensor(0.1565),\n",
            " 'mar_large': tensor(0.1894),\n",
            " 'mar_medium': tensor(0.1101),\n",
            " 'mar_small': tensor(0.0024)}\n"
          ]
        }
      ],
      "source": [
        "# Initialize the metric\n",
        "metric = MeanAveragePrecision(box_format=\"xyxy\", iou_type=\"bbox\", class_metrics=True)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Assuming test_loader is defined\n",
        "for images, targets in tqdm(test_loader, desc=\"Testing\"):\n",
        "    images = list(image.to(device) for image in images)\n",
        "\n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        predictions = model(images)\n",
        "\n",
        "    # Move to CPU (torchmetrics handles CPU/GPU, but consistency is good)\n",
        "    predictions = [{k: v.cpu() for k, v in p.items()} for p in predictions]\n",
        "\n",
        "    # Update the metric with this batch\n",
        "    # targets need to be a list of dicts on the same device as predictions\n",
        "    # If targets are on GPU, move to CPU to match predictions\n",
        "    targets_cpu = [{k: v.cpu() for k, v in t.items()} for t in targets]\n",
        "\n",
        "    metric.update(predictions, targets_cpu)\n",
        "\n",
        "    # Clear GPU cache to prevent OOM errors\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Compute the final metrics over the whole dataset\n",
        "results = metric.compute()\n",
        "\n",
        "# Print results\n",
        "print(f\"mAP (IoU=0.50:0.95): {results['map']:.4f}\")\n",
        "print(f\"mAP (IoU=0.50): {results['map_50']:.4f}\")\n",
        "print(f\"mAP (IoU=0.75): {results['map_75']:.4f}\")\n",
        "\n",
        "# Since it is single class, you can also look at 'map_per_class'\n",
        "# to ensure it matches the overall map\n",
        "pprint(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1YtO0ynYDMzA",
      "metadata": {
        "id": "1YtO0ynYDMzA"
      },
      "outputs": [],
      "source": [
        "wandb.log(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "FwVVLNO6C8WY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "FwVVLNO6C8WY",
        "outputId": "211bd885-c37a-489c-ff4a-b18f1e6457ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>classes</td><td>▁</td></tr><tr><td>map</td><td>▁</td></tr><tr><td>map_50</td><td>▁</td></tr><tr><td>map_75</td><td>▁</td></tr><tr><td>map_large</td><td>▁</td></tr><tr><td>map_medium</td><td>▁</td></tr><tr><td>map_per_class</td><td>▁</td></tr><tr><td>map_small</td><td>▁</td></tr><tr><td>mar_1</td><td>▁</td></tr><tr><td>mar_10</td><td>▁</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classes</td><td>1</td></tr><tr><td>map</td><td>0.09281</td></tr><tr><td>map_50</td><td>0.21065</td></tr><tr><td>map_75</td><td>0.06797</td></tr><tr><td>map_large</td><td>0.12947</td></tr><tr><td>map_medium</td><td>0.03342</td></tr><tr><td>map_per_class</td><td>0.09281</td></tr><tr><td>map_small</td><td>0.00348</td></tr><tr><td>mar_1</td><td>0.00543</td></tr><tr><td>mar_10</td><td>0.04162</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vanilla-fasterrcnn-experiment</strong> at: <a href='https://wandb.ai/warwick-team/selva-box-tree-detection/runs/rzba8qg6' target=\"_blank\">https://wandb.ai/warwick-team/selva-box-tree-detection/runs/rzba8qg6</a><br> View project at: <a href='https://wandb.ai/warwick-team/selva-box-tree-detection' target=\"_blank\">https://wandb.ai/warwick-team/selva-box-tree-detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260115_190535-rzba8qg6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aL9QE-V0DPd3",
      "metadata": {
        "id": "aL9QE-V0DPd3"
      },
      "source": [
        "# Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "176abd95",
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize prediction and ground truth on some test images side by side\n",
        "model.eval()\n",
        "for images, targets in tqdm(test_loader, desc=\"Visualizing Predictions\"):\n",
        "    images = list(image.to(device) for image in images)\n",
        "\n",
        "    # Forward pass\n",
        "    with torch.no_grad():\n",
        "        predictions = model(images)\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        img = images[i].cpu()\n",
        "        gt_boxes = targets[i][\"boxes\"].cpu()\n",
        "        pred_boxes = predictions[i][\"boxes\"].cpu()\n",
        "        pred_scores = predictions[i][\"scores\"].cpu()\n",
        "\n",
        "        # Filter predictions with a threshold (e.g., 0.5)\n",
        "        threshold = 0.5\n",
        "        keep_idxs = pred_scores >= threshold\n",
        "        pred_boxes = pred_boxes[keep_idxs]\n",
        "        pred_scores = pred_scores[keep_idxs]\n",
        "\n",
        "        # Plot ground truth\n",
        "        print(\"Ground Truth:\")\n",
        "        plot_image(\n",
        "            img,\n",
        "            boxes=gt_boxes,\n",
        "            class_names=[\"Tree\"],\n",
        "            show=True,\n",
        "        )\n",
        "\n",
        "        # Plot predictions\n",
        "        print(\"Predictions:\")\n",
        "        plot_image(\n",
        "            img,\n",
        "            boxes=pred_boxes,\n",
        "            scores=pred_scores,\n",
        "            class_names=[\"Tree\"],\n",
        "            show=True,\n",
        "        )\n",
        "\n",
        "    break  # Remove this break to visualize more batches"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "selva-box-tree-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
